整體流程
![](/readmeimages/procedure.png)

step1. 在開始跑主程式碼前需要先做資料蒐集與前處理
1.蒐集比賽影片，以不同攝影機多種角度拍攝比賽場地之影片
2.製作遮罩，先擷取錄製好的比賽場地之畫面，描取畫面中在場地的四個角落，形成矩形，將在場內的圖像顏色更改成白色，場外圖像更改成黑色
3.將比賽影片加上遮罩，過濾掉不需追蹤之物件，例如觀眾、場外的球、移動的工作人員等
![](/readmeimages/addmask.png)
4.以YOLOv7模型遮測物件，包含人、球與三角錐，為後續步驟做使用，並同時將拍攝到的比賽影片Fine-tuning YOLOv7模型，增加模型泛化性
5.製作平面圖(本程式碼以標準足球場為例)

step2. 準備程式碼所需資訊  
可參考[](./taiyuan_info)或 [](./xian_info)裡的程式碼，自行更換資訊，包含
1.原始影片與平面圖上的對應點
  *由於我們需要將多個攝影機畫面整合到一個平面圖上，需要使用點對點映射的方法，所以要預先紀錄原始影片上的點與映射到平面圖上的對應點
2.原始影片相關資訊
3.原始影片跑完YOLOv7模型的json檔案
4.產出影片資訊
5.要放在畫面上的數據位置
6.平面圖資訊
7.其他判別人物隊伍相關資訊

step3. 執行程式
(--config後自行更改路徑)
```
python3 main.py --config xian_info/info_0615_game1.yaml
```
1.人物分隊
  *利用人的座標點，擷取出人物身上穿的球衣部分，在HSV色彩空間分群結果最為精確，於是將截取出的球衣部分轉換成HSV色彩空間，並對此區塊做白平衡處理，可以減少光照對顏色變化的影響，再採用K-means Clustering 進行分群，得到該球員之隊伍，區分出場上比賽球員的所屬隊伍
  ![](/readmeimages/addWB.png) ![](/readmeimages/kmeans.png)
2.物件追蹤
  *需要做追蹤的物件有球員與球。在球員匹配演算法中，有分為追蹤到的球員(有固定數量)以及在深度學習偵測到的球員，追蹤球員會與偵測球員互相匹配，以偵測到的球員資訊去更新追蹤球員資訊。偵測到的球
員所需取得的數據有：**1.原始畫面偵測到的人物座標、2.原始畫面映射到2D平面戰術板的座標、3.所屬攝影機的ID、4.分隊結果**；追蹤球員所需取得的數據有：**1.在2D平面戰術板上的座標位置、2.所屬隊伍、3.最高速度、4.加速度、5.傳球成功率、6.穩定與遺失幀數**。首先，將在深度學習偵測的物件座標映射轉換到2D球場平面圖上，以利後續進行分析使用者所需數據，同時使用這些映射後的座標，與前一幀追蹤到的球員，依照兩者在戰術板上的座標最短距離、覆蓋面積、所屬隊伍與追蹤球員的遺失時間，組成一個成本矩陣(cost matrix)，並以**匈牙利演算法**，匹配出追蹤球員與最吻合的偵測球員，達到 ReID 以及追蹤的效果，當球員在比賽中被遮擋時，也能利用**成本矩陣**去判斷最符合的球員，重新追回。同時以匹配到的偵測球員數據更新追蹤球員數據，並根據記錄下的數據計算出**最高速度、加速度與傳球成功率**等數據。球的部分，也同樣使用映射到戰術板上的座標，將當前幀偵測到的球與前一幀追蹤到的球依照在戰術板上的座標最小距離做匹配，達到追蹤，並根據球的穩定幀數與追蹤球與偵測求在平面板之間距離判斷是否偵測到的球有抓錯，同時根據**追蹤球員座標與球的座標**，判斷球與哪個球員最為接近，進可得到持球隊伍與持球球員，以利算出**球員的傳球成功率與隊伍的連續傳球次數、截球次數**。
 ![](/readmeimages/track.png)
4.數據生成分析與數據視覺化
  *因為教練需要精進球員，而提出部分所需數據，例如**球員個人的跑速、加速度、跑動距離、傳球成功率**等，以及**隊伍的連續傳球次數、截球次數**等。在物件追蹤中，球員與球的資訊皆被記錄下來，根據更新的球員與球的資訊，自動計算出客觀的量化數據，並將球員與球在2D平面圖上的點座標繪製出來，進可得知**球員彼此的相對位置、移動方向，以及球的移動軌跡**，使用者觀看平面圖便能做戰術規劃。最後，將原始比賽影片、戰術板與數據紀錄串流至網站上，方便使用者查看。
 ![](/readmeimages/board.png)  ![](/readmeimages/show.png)



